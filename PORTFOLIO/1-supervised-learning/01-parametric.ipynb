{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Linear Models",
   "id": "292485ce153e62ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T07:20:01.363336Z",
     "start_time": "2024-08-30T07:20:01.359928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# synthetic data for the rest of the linear models:\n",
    "np.random.seed(5)\n",
    "n = 100 # samples\n",
    "p = 5 # features\n",
    "sigma = 0.2 # std\n",
    "X = np.random.normal(0, 1, size=(n,p))\n",
    "beta_true = np.random.randint(-4, 2, p)\n",
    "noise = np.random.normal(0, sigma, size=(n))\n",
    "y = X @ beta_true + noise"
   ],
   "id": "17bee27c05b457d9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Ordinary Least Squares (OLE)\n",
    "\n"
   ],
   "id": "8001d7b7f4e98d12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analytical Method:",
   "id": "ac64e740de0c0037"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\\begin{align*}\\hat{\\beta} &= \\arg \\min_{\\beta} \\frac{1}{n}\\|y-X \\beta\\|^2_2\\\\\n",
    " &= (X^TX)^{-1}X^T y\\end{align*}\n",
    " $$"
   ],
   "id": "909c5babbe8a868c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T07:20:04.094490Z",
     "start_time": "2024-08-30T07:20:04.091079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "betahat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "print(\"betahat: \", betahat)\n",
    "print(\"beta true:\", beta_true)"
   ],
   "id": "c53fa60c632c17b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betahat:  [-2.94946726  0.01589149 -2.004408   -3.97428268 -3.99637663]\n",
      "beta true: [-3  0 -2 -4 -4]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Analysis\n",
    "realise that `beta_true` is now obfuscated with noise, thus you will never be able to retrieve it perfectly."
   ],
   "id": "9761e1bde491cb04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradient Descent:",
   "id": "625890a4f7c51394"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Motivations:\n",
    "sometimes, you cannot explicitly solve the `argmin` formulation of the parameters in closed form. also, sometimes calculating the entire analytic solution may be too computationally intensive, and thus gradient descent is a fantastic technique.\n",
    "\n",
    "note that there are two flavours:\n",
    "\n",
    "Stochastic Gradient Descent:\n",
    "$$\\hat{\\beta}^{(k+1)} = \\hat{\\beta}^{(k)} - \\eta\\nabla_\\beta L (\\hat{\\beta}^{(k)})$$\n",
    "\n",
    "in which we iterate only over 1 sample at a time, and,\n",
    "\n",
    "Batch Gradient Descent:\n",
    "$$$$\n",
    "\n",
    "in which we iterate over the entire dataset.\n",
    "\n",
    "Note, in practice you will choose **mini-batch Gradient Descent**, which is a mediation of both these approaches:\n",
    "$$$$"
   ],
   "id": "6fa254a8bc817703"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for this problem:\n",
    "$$\n",
    "\\nabla_\\beta L(\\beta) = -2 X^T y + 2X^TX\\beta,\n",
    "$$\n"
   ],
   "id": "75154466e3b10972"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T07:34:35.436572Z",
     "start_time": "2024-08-30T07:34:35.432544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eta = 0.001                         # learning stepsize\n",
    "T = 50                              # number of iterations\n",
    "\n",
    "def grad_loss(b, X, y):\n",
    "    return -2 * X.T @ y + 2 * X.T @ X @ b\n",
    "\n",
    "betas = np.zeros(shape=(T,p))       # initialised as p-dimensional vector of 0's\n",
    "\n",
    "for t in range(1, T):\n",
    "    betas[t,:] = betas[t-1,:] - eta * grad_loss(betas[t-1,:], X, y)\n",
    "    \n",
    "print(\"beta batch GD: \", betas[T-1,:])\n",
    "print(\"beta true: \", beta_true)"
   ],
   "id": "293ac05e29032d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta batch GD:  [-2.94939435  0.01570463 -2.00406754 -3.97354862 -3.99569519]\n",
      "beta true:  [-3  0 -2 -4 -4]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ridge Regression",
   "id": "2bc0e08ceadcbe94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lasso Regression",
   "id": "1544efb4906d8e1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7efe000eb7233212"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
